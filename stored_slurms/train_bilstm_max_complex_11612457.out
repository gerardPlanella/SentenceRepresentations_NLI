[nltk_data] Downloading package punkt to /home/lcur1136/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Found cached dataset snli (/home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)
Models running on device:  cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 626.33it/s]
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-26da30925fbad333.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-030550b06704f0a9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-5f71913ab959d4e9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-d4ba7e085145c696.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a34bde53a6f7997e.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a056c3b7d52f421a.arrow
Loading saved Vocabulary from dataset/vocab.pickle
SentenceClassifier(
  (embed): Embedding(33146, 300)
  (encoder): BiLSTMEncoder(
    (enc_lstm): LSTM(300, 2048, bidirectional=True)
  )
  (layers): Sequential(
    (0): Linear(in_features=16384, out_features=512, bias=True)
    (1): Tanh()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): Tanh()
    (4): Linear(in_features=512, out_features=3, bias=True)
  )
)
Adjusting learning rate of group 0 to 1.0000e-01.
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [15:09<4:47:59, 909.46s/it] 10%|█         | 2/20 [30:23<4:33:42, 912.37s/it] 15%|█▌        | 3/20 [45:07<4:14:49, 899.40s/it] 20%|██        | 4/20 [59:41<3:57:10, 889.39s/it] 25%|██▌       | 5/20 [1:14:54<3:44:26, 897.76s/it] 30%|███       | 6/20 [1:30:04<3:30:27, 901.93s/it] 35%|███▌      | 7/20 [1:45:11<3:15:48, 903.71s/it] 40%|████      | 8/20 [2:00:26<3:01:24, 907.08s/it] 45%|████▌     | 9/20 [2:15:34<2:46:22, 907.46s/it] 50%|█████     | 10/20 [2:30:33<2:30:47, 904.71s/it] 55%|█████▌    | 11/20 [2:45:13<2:14:36, 897.36s/it] 55%|█████▌    | 11/20 [2:59:57<2:27:14, 981.58s/it]
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 6114.393286496401
Validation Loss: 86.63922882080078
Validation Accuracy: 0.772505588295062
new highscore
Adjusting learning rate of group 0 to 1.9800e-02.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 4441.212639063597
Validation Loss: 80.15985107421875
Validation Accuracy: 0.7909977646819752
new highscore
Adjusting learning rate of group 0 to 3.9204e-03.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3831.664702758193
Validation Loss: 77.37006378173828
Validation Accuracy: 0.803088803088803
new highscore
Adjusting learning rate of group 0 to 7.7624e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3587.8817415237427
Validation Loss: 77.55696868896484
Validation Accuracy: 0.8057305425726479
new highscore
Adjusting learning rate of group 0 to 1.5370e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3528.7711485624313
Validation Loss: 77.60001373291016
Validation Accuracy: 0.8055273318431213
Adjusting learning rate of group 0 to 1.5216e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3517.2180876880884
Validation Loss: 77.66146087646484
Validation Accuracy: 0.8052225157488315
Adjusting learning rate of group 0 to 1.5064e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3506.3392720371485
Validation Loss: 77.69709014892578
Validation Accuracy: 0.8047144889250153
Adjusting learning rate of group 0 to 1.4913e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3495.6508322656155
Validation Loss: 77.69896697998047
Validation Accuracy: 0.8059337533021743
new highscore
Adjusting learning rate of group 0 to 2.9528e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3484.1034363359213
Validation Loss: 77.72490692138672
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.9233e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3481.975564479828
Validation Loss: 77.73489379882812
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.8940e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3479.972256362438
Validation Loss: 77.73979949951172
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.8651e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3477.913671821356
Validation Loss: 77.74826049804688
Validation Accuracy: 0.8060353586669377
new highscore
Training stopped due to LR limit.
Loading best model to test...
Test Accuracy: 0.8012011400651465
