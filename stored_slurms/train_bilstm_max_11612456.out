[nltk_data] Downloading package punkt to /home/lcur1136/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Found cached dataset snli (/home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)
Models running on device:  cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 70.77it/s]
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-26da30925fbad333.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-030550b06704f0a9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-5f71913ab959d4e9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-d4ba7e085145c696.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a34bde53a6f7997e.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a056c3b7d52f421a.arrow
Loading saved Vocabulary from dataset/vocab.pickle
SentenceClassifier(
  (embed): Embedding(33146, 300)
  (encoder): BiLSTMEncoder(
    (enc_lstm): LSTM(300, 2048, bidirectional=True)
  )
  (layers): Sequential(
    (0): Linear(in_features=16384, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=3, bias=True)
  )
)
Adjusting learning rate of group 0 to 1.0000e-01.
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [15:10<4:48:26, 910.89s/it] 10%|█         | 2/20 [30:27<4:34:15, 914.20s/it] 15%|█▌        | 3/20 [45:43<4:19:13, 914.89s/it] 20%|██        | 4/20 [1:01:03<4:04:35, 917.21s/it] 25%|██▌       | 5/20 [1:16:13<3:48:36, 914.44s/it] 30%|███       | 6/20 [1:30:54<3:30:43, 903.08s/it] 35%|███▌      | 7/20 [1:45:21<3:13:06, 891.24s/it] 40%|████      | 8/20 [2:00:03<2:57:39, 888.28s/it] 45%|████▌     | 9/20 [2:15:04<2:43:36, 892.39s/it] 50%|█████     | 10/20 [2:30:00<2:28:53, 893.37s/it] 55%|█████▌    | 11/20 [2:45:00<2:14:18, 895.44s/it] 60%|██████    | 12/20 [3:00:01<1:59:38, 897.32s/it] 65%|██████▌   | 13/20 [3:15:03<1:44:49, 898.51s/it] 70%|███████   | 14/20 [3:29:56<1:29:42, 897.07s/it] 75%|███████▌  | 15/20 [3:44:57<1:14:50, 898.19s/it] 80%|████████  | 16/20 [3:59:58<59:55, 898.95s/it]   85%|████████▌ | 17/20 [4:15:01<45:00, 900.16s/it] 90%|█████████ | 18/20 [4:29:27<29:40, 890.02s/it] 95%|█████████▌| 19/20 [4:43:53<14:42, 882.61s/it]100%|██████████| 20/20 [4:58:22<00:00, 878.72s/it]100%|██████████| 20/20 [4:58:22<00:00, 895.14s/it]
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 6095.802386641502
Validation Loss: 89.72636413574219
Validation Accuracy: 0.7605161552529973
new highscore
Adjusting learning rate of group 0 to 1.9800e-02.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 4444.7380157113075
Validation Loss: 78.75517272949219
Validation Accuracy: 0.7997358260516155
new highscore
Adjusting learning rate of group 0 to 3.9204e-03.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3827.485727444291
Validation Loss: 77.85255432128906
Validation Accuracy: 0.8035968299126194
new highscore
Adjusting learning rate of group 0 to 7.7624e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3585.2711868286133
Validation Loss: 77.84233856201172
Validation Accuracy: 0.805019305019305
new highscore
Adjusting learning rate of group 0 to 1.5370e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3525.698278814554
Validation Loss: 77.83128356933594
Validation Accuracy: 0.8043080674659622
Adjusting learning rate of group 0 to 1.5216e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3514.184953689575
Validation Loss: 77.86699676513672
Validation Accuracy: 0.8044096728307255
Adjusting learning rate of group 0 to 1.5064e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3503.2256156355143
Validation Loss: 77.88542938232422
Validation Accuracy: 0.8047144889250153
Adjusting learning rate of group 0 to 1.4913e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3492.708216279745
Validation Loss: 77.93893432617188
Validation Accuracy: 0.804612883560252
Adjusting learning rate of group 0 to 1.4764e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3482.3893654495478
Validation Loss: 77.9506607055664
Validation Accuracy: 0.805019305019305
Adjusting learning rate of group 0 to 1.4616e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3472.2348552793264
Validation Loss: 77.99523162841797
Validation Accuracy: 0.8048160942897785
Adjusting learning rate of group 0 to 1.4470e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3462.3442564606667
Validation Loss: 78.0356674194336
Validation Accuracy: 0.8057305425726479
new highscore
Adjusting learning rate of group 0 to 2.8651e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3450.7776627093554
Validation Loss: 78.04753875732422
Validation Accuracy: 0.8056289372078845
Adjusting learning rate of group 0 to 2.8364e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3448.7908298820257
Validation Loss: 78.03501892089844
Validation Accuracy: 0.8054257264783581
Adjusting learning rate of group 0 to 2.8081e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3446.8638137876987
Validation Loss: 78.05658721923828
Validation Accuracy: 0.8055273318431213
Adjusting learning rate of group 0 to 2.7800e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3444.925933510065
Validation Loss: 78.08016204833984
Validation Accuracy: 0.8052225157488315
Adjusting learning rate of group 0 to 2.7522e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3443.0374713391066
Validation Loss: 78.06036376953125
Validation Accuracy: 0.8054257264783581
Adjusting learning rate of group 0 to 2.7247e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3441.1621244996786
Validation Loss: 78.08930206298828
Validation Accuracy: 0.8055273318431213
Adjusting learning rate of group 0 to 2.6974e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3439.3032297343016
Validation Loss: 78.0834732055664
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.6704e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3437.4663324207067
Validation Loss: 78.09037780761719
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.6437e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 3435.689810216427
Validation Loss: 78.09634399414062
Validation Accuracy: 0.8057305425726479
Adjusting learning rate of group 0 to 2.6173e-05.
Loading best model to test...
Test Accuracy: 0.8048656351791531
