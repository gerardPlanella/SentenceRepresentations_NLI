[nltk_data] Downloading package punkt to /home/lcur1136/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Found cached dataset snli (/home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)
Models running on device:  cuda
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 621.35it/s]
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-26da30925fbad333.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-030550b06704f0a9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-5f71913ab959d4e9.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-d4ba7e085145c696.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a34bde53a6f7997e.arrow
Loading cached processed dataset at /home/lcur1136/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b/cache-a056c3b7d52f421a.arrow
Loading saved Vocabulary from dataset/vocab.pickle
SentenceClassifier(
  (embed): Embedding(33146, 300)
  (encoder): BiLSTMEncoder(
    (enc_lstm): LSTM(300, 2048, bidirectional=True)
  )
  (layers): Sequential(
    (0): Linear(in_features=16384, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=3, bias=True)
  )
)
Adjusting learning rate of group 0 to 1.0000e-01.
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [11:58<3:47:32, 718.58s/it] 10%|█         | 2/20 [24:03<3:36:42, 722.36s/it] 15%|█▌        | 3/20 [36:06<3:24:42, 722.52s/it] 20%|██        | 4/20 [48:04<3:12:15, 720.99s/it] 25%|██▌       | 5/20 [1:00:01<2:59:50, 719.39s/it] 30%|███       | 6/20 [1:11:54<2:47:19, 717.12s/it] 35%|███▌      | 7/20 [1:23:52<2:35:27, 717.49s/it] 40%|████      | 8/20 [1:35:48<2:23:26, 717.19s/it] 45%|████▌     | 9/20 [1:47:43<2:11:19, 716.34s/it] 50%|█████     | 10/20 [1:59:38<1:59:20, 716.03s/it] 50%|█████     | 10/20 [2:11:34<2:11:34, 789.46s/it]
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 7200.985418796539
Validation Loss: 112.91157531738281
Validation Accuracy: 0.682483235114814
new highscore
Adjusting learning rate of group 0 to 1.9800e-02.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5793.446278065443
Validation Loss: 106.03866577148438
Validation Accuracy: 0.7104247104247104
new highscore
Adjusting learning rate of group 0 to 3.9204e-03.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5360.451046794653
Validation Loss: 101.26715087890625
Validation Accuracy: 0.7276976224344646
new highscore
Adjusting learning rate of group 0 to 7.7624e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5217.900483906269
Validation Loss: 101.02915954589844
Validation Accuracy: 0.7289168868116237
new highscore
Adjusting learning rate of group 0 to 1.5370e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5183.779768913984
Validation Loss: 100.90813446044922
Validation Accuracy: 0.7289168868116237
Adjusting learning rate of group 0 to 1.5216e-04.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5177.092129290104
Validation Loss: 100.89067840576172
Validation Accuracy: 0.7297297297297297
new highscore
Adjusting learning rate of group 0 to 3.0127e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5170.316556066275
Validation Loss: 100.89058685302734
Validation Accuracy: 0.7295265190002032
Adjusting learning rate of group 0 to 2.9826e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5169.022017091513
Validation Loss: 100.88982391357422
Validation Accuracy: 0.7295265190002032
Adjusting learning rate of group 0 to 2.9528e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5167.806576132774
Validation Loss: 100.896484375
Validation Accuracy: 0.7297297297297297
Adjusting learning rate of group 0 to 2.9233e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5166.616659134626
Validation Loss: 100.88146209716797
Validation Accuracy: 0.7296281243649665
Adjusting learning rate of group 0 to 2.8940e-05.
Shuffling training data
Batch number 1000
Batch number 2000
Batch number 3000
Batch number 4000
Batch number 5000
Batch number 6000
Batch number 7000
Batch number 8000
Training Loss: 5165.419783771038
Validation Loss: 100.89673614501953
Validation Accuracy: 0.7298313350944929
new highscore
Training stopped due to LR limit.
Loading best model to test...
Test Accuracy: 0.727707654723127
